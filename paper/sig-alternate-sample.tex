% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{hyperref}

\begin{document}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\doi{10.475/123_4}

% ISBN
\isbn{123-4567-24-567/08/06}

%Conference
\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

%\acmPrice{\$15.00}

%
% --- Author Metadata here ---
\conferenceinfo{UofM:CoE:EECS}{2015, Ann Arbor MI}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{High Concurreny B-Trees for Insert Heavy Workloads}
\subtitle{An in-depth comparison}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Isaac Bowen\titlenote{A note about this author}\\
       \affaddr{University of Michigan}
		\affaddr{College of Engineering}
		\affaddr{MSE: Computer Science and Engineering}
       \email{irbowen@umich.edu}
% 2nd. author
\alignauthor
G.K.M. Tobin\titlenote{The secretary disavows
any knowledge of this author's actions.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{P.O. Box 1212}\\
       \affaddr{Dublin, Ohio 43017-6221}\\
       \email{webmaster@marysville-ohio.com}
}

\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
\href{http://github.com/irbowen/b_trees}{Code can be found here}
Fill this in once we're done\\ \\
You should try to write the best research paper that you can using the results of your project. You have read many good papers throughout this class, so by this point you should have a good idea of what makes a good research paper! Basically, your report needs to clearly present the following:
\begin{enumerate}
\item the problem statement
\item The motivation, why its important
\item The literature review (the previous work in this area
\item Main idea and approach
\item Implementation techniques
\item Experimental setup
\item Results
\end{enumerate}
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


%
% End generated code
%

%
%  Use this command to print the description
%
%\printccsdesc

% We no longer use \terms command
%\terms{Theory}

%\keywords{ACM proceedings; \LaTeX; text tagging}
\keywords{B-Trees, Reader Writer Locks, B-Link, Lock-Free}

\section{Introduction/Motivation}
Databases systems are usually run in multiple threads or processes, so that they can handle many users at the same time, take advantage of multiple processor cores, and using async I/O, multiple disks \cite{graefe:survey}.  Systems will larger number of processors, and cores-per-processor are becoming more common, and main memories are becoming much larger.  B-trees were first built for single-threaded DBMS, which stored everything on disks - including the index itself.  Later systems allowed the index to fit in memory, and allowed some concurrency - multiple threads could read from the index.

We attempt to look B-Tree's for insert-heavy workloads. WE WILL ASSUME THE INDEX, OR THE WHOLE DB, CAN FIT IN MEMORY
It should be noted that we are not looking at transactional level locking, but concurrent execution within a transaction, or in a transaction free environment.  We are not concerned, then, with provide any kind of predicate locks to potect against "phantom" inserts.

\section{Previous Work}
B-trees have long been the primary access data structure for databases, file systems, and various other systems because of their logarithmic \texttt{insert()} and \texttt{get()}.
They also have a host of other properties that make them also for large systems.  A short list: 
\begin{enumerate}
\item Maintain everything in order.  This means that merge operations can be done without sort, and SMJ, and often used join in database systems, is very efficient
\item Block access.  The structure can store as much data is it can on a single page, and doing locking on a single page.  This made B-Tree's very popular early on, when database's could not fit in memory, and had to be dumped onto disk.
\end{enumerate}

Over there 40 year history, there have been many different variations and flavors of B-Trees.  The original version of this data structure stored data in both the leaf and inner nodes.  These structures were optimized for block access - the entire b-tree index could not fit into memory, and the fact that its nodes size could be made to match the disk block size.  This, coupled with buffer pools, made them the dominant structure even in early database systems.

Later versions (B*Trees or B+Trees, depending on who you ask) stored all the data in leaf nodes, and the inner nodes served only as lookup keys.  Later version would ensure the entire tree was height balanced, and put pointers on the leaf nodes so that scan could be done with only one tree traversal.  

Later (fancier) techniques attempted to put links on inner nodes as well, so that they could do "overflow" nodes, to try to prolong splitting.  The idea here was that when a key was inserted into a node that should then split, it would look at its neighbors in the same  of the tree. If they have enough room, the node could offload some of its keys and values onto its siblings.  This could allow the tree to become more 'full' - the average occupancy of each node will be higher - before nodes split.  Depending on the cost of splitting, and the number that occur, this could provide a benefit to performance.

There have been a few approaches to locking in B-Trees so far.

The first, naive, approach, is to lock any node that could split on an insert.  However, since any split could propagate all the way back up to the root node, each insert would need to have an exclusive lock on every node that it touches - making the tree single threaded.

Another slightly better way to do locking is to acquire a shared lock at first, and then scan through the node to find where the key will be inserted.  If the child not cannot spit, than we can hold an shared lock on the node while the rest of the insert finishes in the tree below.  If the child can split, we must hold an exclusive lock.  The reader will notice that this can still lead to high lock contention on the root node, especially with small fan out.

\section{Our Approach}
We first wanted to see what worked well on a sequential model, so that we can compare those same factors on our concurrent models.

We knew that we wanted to be able to test the effect of the fan out of the nodes - what size of fan out favors insert-heavy workloads? We decided to test the fan out of the inner nodes, and the number of data elements stored in a leaf node separately.  We plan on seeing whether one of these fan outs has more of an input on performance.  Both of these constants can be modified in \texttt{node.h}

We also want to see what the performance is under different read and write percentage workloads.  We use \texttt{std::rand()} to decide if a given operation should be a read or write in our testing setup.  This value is input into the program through standard input at start up.

There were a few things that we decided to change, given that this tree is to be optimized for writes instead of reads.  
We do not concern ourselves with keeping all the leaf nodes at equal depth.  This makes sense for reads - you want to make sure each key get be access in the same amount of time, and if you are trying to get multiple elements, you can do the lookup once and then just scan across the leaf nodes.  However, maintain this global depth is expensive in the face of multiple threads.  We chose to abandon this requirement, and let the tree have varying depths of nodes - the root node could point to some leaf nodes, and other trees with various children.  This could increase lookup time (as well as insert time, since it must do at lookup to find the insert location, however, as long as the key values are not VERY skewed, the tree should perform well.)  We believe that additional lookup time is not a problem, as long as it is concurrent - the real performance limitation is when the tree structure must change, because this requires exclusive locks.  If we can keep the "structure" of the tree the same, then we can maximize for inserts, and always have some number of threads doing something useful, instead of waiting as the tree is balanced.

Many B-Tree implement pointers to the neighboring nodes at the same level, both for leaf and inner nodes.  While this is certainly helpful for range-based read workloads, there is a cost that has to be paid on every insert.  In an insert-heavy workload, these become much more important.  Also, in the inner nodes, these pointers are used to push of the tree splitting, to lower cost.  This was assuming, however, that the tree was balanced.  Without this invariant, there is no reason to do this.  In concurrent code, managing all of these pointers become incredibly difficult to do correctly, and has minimal benefit.  Therefore, we decided to forgo these pointers.  This means that range queries become less efficient, because we can no longer scan across the leaf nodes.  However, for an insert heavy workload, range queries are not well defined.  They would require some form of predicate locking, MVCC, or some other complication that we do not want - simple put, workloads that are insert heavy should know that range based queries do not make sense, as the data is always being changed.

\section{Architecture}
What all did we have to build to make this work and test out our ideas?
\begin{itemize}
  \item{Testing Framework:} We want to test the system at different levels of
    \begin{itemize}
      \item Input Size
      \item Number of Threads
      \item Read Write Percent Workload
      \item Fan out on inner nodes
      \item Data slots on leaf nodes
    \end{itemize}
    To testing all of these things, I will be creating a dope ass main.ccp that can read input from test ases
  \item{Sequential Tree:} We had to build a simple, single-thread B-tree first.  We built on this for our other version, and will also use it as the baseline for testing.
  \item{ReaderWriter Tree:} This tree uses different kinds of locks, shared and exclusive, and also does checking to see if the child node can split, to see if this node is "safe" from splitting.  This version uses \texttt{std::list<>} within the nodes
  \item{ReaderWriter Array:} How does sequential access of nodes affect performance?  We'll see.  We would think that as the size of the inner and leaf node fannout increases, the array based B-Tree should perform better and better compared to the list based tree.   Could this show promise for further extension - putting the whole B-tree into an array?
  \item{BLink Tree:} This structure is different in that it insert into the leaf node, and acquires locks on the way back up
\end{itemize}

\section{Implementation and Test Setup}
We impmented our B-Trees in \texttt{C++}, using new features only available in \texttt{C++14}, most notably \texttt{stdshared\_time\_mutex}, which allows both exclusive and shared locking.  This requires a compiler with \texttt{gc -4.9} or greater.  Because this is so new, few systems have made version 4.9 available - it is not available on \texttt{bigdata.eecs.umich.edu}, for example, we decided to set up our own testing environment.

We set up a virtual machine using Oracle Virtual Box.  The VM is running Ubunutu Server 15.10 with gcc 4.9.3.  The host system is a Windows 7 machine with a FX-8350 (\texttt{8 cores @ 4Ghz}) and 32GB of RAM.  We allocated 4 cores and 24GB of RAM to the VM.  All test were run with minimal applications running on the Windows side.

\section{Performance}
We tested all of our implementations under several different conditions.

We begin with our sequential tree implementation, so that we have a baseline to compare our concurrent versions to.  \\

Sequential Tree, F = 4\\
\begin{tabular}{| l | r |}
  \hline
  Input Size & Time (ms)\\  \hline
  1000			&	2	\\
  10000			&	12	\\
  100000		&	80	\\
  1000000		&	586	\\
  10000000		&	5620	\\
  100000000		&	59000	\\
  \hline
\end{tabular} \\

Sequential Tree, F = 16\\
\begin{tabular}{| l | r |}
  \hline
  Input Size & Time (ms)\\  \hline
  1000			&	2	\\
  10000			&	20	\\
  100000		&	123	\\
  1000000		&	754	\\
  10000000		&	7045	\\
  100000000		&	70318	\\
  \hline
\end{tabular} \\

Sequential Tree, F = 64\\
\begin{tabular}{| l | r |}
  \hline
  Input Size & Time (ms)\\  \hline
  1000			&	4	\\
  10000			&	31	\\
  100000		&	283	\\
  1000000		&	3607	\\
  10000000		&	128447	\\
  100000000		&	384118\\
  \hline
\end{tabular} \\

Sequential Tree, F = 256\\
\begin{tabular}{| l | r |}
  \hline
  Input Size & Time (ms)\\  \hline
  1000			&	7	\\
  10000			&	67	\\
  100000		&	968	\\
  1000000		&	14840	\\
  10000000		&	267131	\\
  100000000		&	2543760	\\
  \hline
\end{tabular}\\

Note the dramatic difference in performance as the fannout increases. 
We discuss the significance of these results in the next section.\\

We wanted to compare are tree to standard implementations to a standard, to verify that our concurrent versions were not built on top of something slow.  To that end, we compared it to std::map on gcc 4.9.3.

\texttt{std::map}\\
\begin{tabular}{| l | r |}
  \hline
  Input Size & Time (ms)\\  \hline
  1000			&	1	\\
  10000			&	6	\\
  100000		&	63	\\
  1000000		&	720	\\
  10000000		&	12780	\\
  100000000		&	228835	\\
  \hline
\end{tabular}\\

\section{Discussion}
It is curious that the fannout increases seems to slow things down


- Stonebraker is right - locking is bad, single threads fast to completion is better
- Fan out is bad
	- We though fannout would help cache, but it turns out not
	- Based on old schol block access with buffer pool
	- Now, its all in memory - hoping down a few levels of trees doesn't matter


\section{Citations}
Some papers that we read to give ourselves background on the topics:
\begin{itemize}
  \item "Concurrent B-trees with Lock-free Techniques"\cite{sultana:lockfree} gives us the inspiration for the lock free B-tree.  They, however, didn't not have access to the large memory, built in C++14 atomics, and they were not focusing on writes - they were trying to build a general purpose lock free btree for NUMA computers.
  \item "A survey of B-tree locking techniques"\cite{graefe:survey}, much like the title says, presents an over of many of the different approaches that have been taken so far.  However, it reallys skims over, almost dismissing, lock free techniques.
  \item "Efficient Locking for Concurrent Operations on B-Trees" \cite{lehman:locking} This one gave us the idea of the \texttt{can\_split()} function, and gave background on reader writer locks and other, etc
  \item "Concurrent Cache-Oblivious B-Trees" \cite{bender:cache} I need to read this one again
  \item "A Concurrent Blink-Tree Algorithm Using a Cooperative Locking Protocl" \cite{lim:blink} Ryan is making this verion
  \item "A paper" A paper
\end{itemize}

\section{Experimental Results}
We will need some tables.  I have some data from the sequential tree

\section{Conclusions}
Conclusions
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
Acknowledgments

\bibliographystyle{plain}
\bibliography{mybib}

\end{document}
